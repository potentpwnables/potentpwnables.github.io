---
title: Why I Quit Meta
author: ''
date: '2021-12-29'
slug: why-i-quit-Meta
categories: []
tags:
  - career
type: ''
subtitle: ''
image: ''
---

In June of 2021 I applied to become a Data Engineer (DE) at Meta, and in August I was so happy to hear that I'd been given the opportunity. By November, I realized I had made a mistake. Not by becoming a DE, but by not understanding what it meant to be a DE at Meta. As I would quickly find out, DEs at Meta are, in my opinion, more aptly described as [Analytics Engineers](https://towardsdatascience.com/analytics-engineer-the-newest-data-career-role-b312a73d57d7), and this just wasn't what I was looking for in my career. What follows is not an attempt to dissuade you from working at the company or anything, but instead is an honest attempt at describing why I don't think the role was right for me. My hope is that this provides some perspective for you if you're considering taking a DE job at Meta, or even if you are currently a DE there and wondering if what you're experiencing is unique to you. 

## The Lifecycle of Data
There are, at least according to the [Harvard Business Review](https://online.hbs.edu/blog/post/data-life-cycle), 8 steps in the lifecycle of data, which include generation, collection, processing, storage, management, analysis, visualization, and interpretation. And what I have come to learn is that the stages of collection, processing, and storage are where I get the most joy and motivation. Unfortunately for me, Meta is very heavily invested in the analysis, visualization, and interpretation stages. Their data infrastructure is already built and mature, with a lot of really great tools in place to allow for said analytics. And when that infrastructure needs to be improved, it's typically done by Software Engineers (SWEs). This means that DEs are more focused on facilitating analytics at scale.

The issue for me is that my idea of a great data project is one that offers a solution to problems like "the process we're using to ingest the data is very manual, and we'd like to automate that" or "none of our tools can talk to each other, which makes using data from two different tools in one analysis impossible". However, at Meta, you're much more likely to hear problems like "we'd like to know where the data is for this new metric we want added to the dashboard" or "we'd like to build 10 dashboards, all of which will be virtually identical". And by all means, if analyzing data is what you really like doing, but from a more technical side, then you should absolutely pursue a role there. But if you're someone who likes building bespoke solutions that deal with the data at those earlier stages of its lifecycle, then Meta's likely not the place for you.

## Data at Scale
As I'm sure anyone reading this blog is aware, there are essentially four "V's" in big data: volume, variety, veracity, and velocity (I'm intentionally ignoring the fifth "V" called value). When thinking about using data at scale, the mind typically goes to volume, and if there's one thing that is true about Meta's data, it's that it is massive. And for a lot of people, this is really exciting. Processing data in the size of petabytes is a genuine challenge, and building out solutions that make that data usable can be enjoyable for some. Unfortunately, at least at Meta, these challenges are often solved by software engineers, and not DEs. They're solved through distributed computing, better query engines, heavy investment in data centers, etc. Now, while I'd like to be more involved with those solutions, I think Meta is right to have that handled mostly by SWEs, but, as a result, the biggest challenge I was asked to take on as a DE was optimizing queries so that they didn't hit the memory limit for any given node in the cluster. So with volume being taken care of mostly by SWEs, that really only leaves the other 3 "V's" to be handled by DEs.

**Veracity**  
Dealing with data integrity will always be a key role in any job you take as a DE, but that doesn't mean that it'll take the same form. A lot of the fun and challenge of being a DE, in my opinion, comes from dealing with integrity issues with the data. Is data missing? Is it incomplete? Did I miss an edge case in a parser that I wrote that's causing all of the data to become corrupted? And when you're dealing with a large variety of data, these challenges will certainly come up. But if all of your data is coming from logs generated by your own apps, then there are fewer challenges to deal with. For some (probably the majority), this is a blessing. Not having to deal with the constant struggles that run rampant in wild data means more of your bandwidth can be spent on more meaningful tasks. I, however, am a glutton for punishment and actually find joy in these types of activities, so not being able to engage in them results in me spending less of my time doing what I enjoy. I would much rather spend my time figuring out how to clean up dirty data resulting from manual inputs and coming up with a way to reduce the possibility of that happening in the future than to figure out why a metric has been stuck at 83% for the past week. If you like dealing with mostly clean data, where the biggest headaches are naming conventions and the data types of fields in a table, and where your biggest challenge is figuring out how to merge two tables that both have over a billion records in a single partition, then Meta could be a great opportunity for you. But if you like solving really frustrating data integrity issues, then you might consider working somewhere that faces more data veracity issues.

**Variety**  
As I just mentioned, virtually all of the data you deal with at Meta is generated by products that they own. There are obviously some exceptions, but for the most part the data that you're dealing with on a daily basis is data that is generated in house. This means that on any given day, the only variety I saw in the data was what the data represented. This means that if you're excited about finding common patterns in two different data sets that allow them to be used together, or working with a combination of structured, semi-structured, and/or unstructured data, then you're kind of out of luck. Again, there are exceptions, but the general day to day will include working with data that has been stored in a table. Virtually all of the pipelines for pulling data out of the logs have already been written, so at best you might get to tweak the pipeline a bit, or conduct some optimizations, but building the pipelines from scratch likely won't happen unless you're working on a new product team. Instead, you'll more likely be writing pipelines that combine a few tables together into a summary cube so that dashboard widgets can be populated quickly. For me, this isn't interesting. I'd much rather write a pipeline that pulls data from an API, some CSVs, and an existing database, and stitches them all together to allow an organization to start using the data than simply aggregate some data for a metric. 

**Velocity**  
As you might imagine, Meta generates data at a nearly unprecedented level. With almost 3 billion monthly active users, the amount of data that is generated at any given second is just off the charts. Thankfully, the SWEs have figured out how to process that much data at that speed and get it all written to the graph. As for DEs, our job is to work with batch data, which means that all of the data from the day gets aggregated over night and we get to work with the populated tables the next day. Even if you had hopes of coming in and building out the infrastructure to analyze the data at a faster cadence, you'd quickly learn that Meta has already built this infrasture as well. There are tools in place to analyze the data in real time, generate alerts, etc. And so again, you'd have the opportunity to maybe make some tweaks, or implement a new feature, but for the most part the infrastructure exists. This actually wasn't that big of a problem for me. Handling streaming data sounds incredibly interesting, and if I were to ever want to go somewhere like Netflix this would be a skill set worth having. But for now, it's not an immediate interest of mine, and working with batch data is just fine. So, my only piece of advice here would be that if you're adamant about working with streaming data, then Meta might not be the right place for you. 

## Focus on Impact
When you go through orientation at Meta, they introduce you to a bunch of mantras they have within the company; things like "Move Fast". One of my favorites is "Focus on Impact". I like it because it reminds you to stick to projects for which you think there will be a meaningful outcome. Unfortunately, I've found it difficult to focus on the impact of my work while at Meta. Not because it's not there, but because it just doesn't resonate with me. I work in the Integrity organization, and while the work we do is incredibly important, it doesn't translate well when the work I do is focused on putting metrics on a dashboard. The impact becomes "I made it possible for data scientists to track a number". The real impact, the removal of bad content from Meta's products, is done by other teams, and my team's goal is to measure that work so the other teams can make changes where needed. I can't speak to how it is as a DE in other orgs, but based on conversations I've had, and the training we all have to go through, my assumption is that it's basically the same. 

When I think of making an impact with data, I think of times from my prior roles where I did things like reduce the time it took to ingest data from weeks to minutes, set up alerts to identify fraudulent user activity using a few queries, or built a tool that made identifying new leads for money laundering cases much easier. These projects had real impact that was tangible and observable. These projects made me feel proud of the skill set I was developing, and made me feel like I was making a meaningful contribution. Putting a metric on a dashboard makes me feel like I'm doing grunt work. Only you know what kinds of projects make you feel happy and empowered, and if creating metrics to help others track the important work they're doing is what motivates you, then by all means join Meta. They need you and there is a ton of work to be done. But if that's not your cup of tea, then I'd recommend having some very serious talks with any recruiters, interviewers, or hiring managers about what your day-to-day would look like and decide if that's what you want.

## What Would You Do If You Weren't Afraid
One of the hardest parts about realizing that working as a DE at Meta isn't for me is walking away from such a great company. I know Meta gets a ton of flack in the news about the things they do, but like 80% of it is misrepresentation about what really goes on there. It truly is a great company that's trying to do great things. It genuinely appreciates and takes care of its employees, and has some of the best benefits I have ever seen. And I'm not talking about the basic stuff like salary and health insurance. They're just all around a great company, and walking away from that is incredibly hard. But, another mantra at Meta is "What would you do if you weren't afraid?", and the answer for me is that I would pursue a role more closely aligned with my career goals. Walking away from Meta isn't easy, but I knew that if I stayed there I won't be happy. It's unfortunate that it didn't work out, but I'll forever be grateful for the opportunity to try. Again, I hope I haven't dissuaded you from working there. If working with analytics and really large data are your jam, then there's no better company you could end up at. 